{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioImage Model Zoo Example notebook\n",
    "\n",
    "This notebook shows how to interact with the `bioimgaeio.spec` programmatically to explore, load and export content from the [BioImage Model Zoo](https://bioimage.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "### 0.1 Install dependencies\n",
    "(if in Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    %pip install bioimageio.spec python-devtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Enable pretty validation errors\n",
    "\n",
    "Improves readiblity of format validation errors in Jupyter notebooks by removing redundant error details and hiding calls witin the pydantic library from the stacktrace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec.pretty_validation_errors import (\n",
    "    enable_pretty_validation_errors_in_ipynb,\n",
    ")\n",
    "\n",
    "enable_pretty_validation_errors_in_ipynb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspect the available models in the BioImage Model Zoo\n",
    "\n",
    "Go to https://bioimage.io to browser available models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and inspect a model description\n",
    "\n",
    "bioimage.io resources may be identified via their bioimage.io ID, e.g. \"affable-shark\" or the [DOI](https://doi.org/) of their [Zenodo](https://zenodo.org/) backup.\n",
    "\n",
    "Both of these options may be version specific (\"affable-shark/1\" or a version specific [Zenodo](https://zenodo.org/) backup [DOI](https://doi.org/)).\n",
    "\n",
    "Alternativly any RDF source may be loaded by providing a local path or URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model description with one of these options\n",
    "# 1. version unspecific (implicitly refering to the latest version):\n",
    "MODEL_ID = \"affable-shark\"\n",
    "MODEL_DOI = \"10.5281/zenodo.11092561\"\n",
    "\n",
    "# 2. version specific\n",
    "MODEL_VERSION_ID = \"affable-shark/1\"  # not yet available for this legacy model\n",
    "MODEL_VERSION_DOI = \"10.5281/zenodo.11092562\"\n",
    "\n",
    "# 3. an uploaded draft\n",
    "MODEL_DRAFT = \"affable-shark/draft\"\n",
    "\n",
    "# 4. from source\n",
    "MODEL_URL = \"https://zenodo.org/records/11092562/files/rdf.yaml\"\n",
    "MODEL_PATH = \"some/local/rdf.yaml\"\n",
    "MODEL_PACKAGE_PATH = \"some/local/package.zip\"  # with an rdf.yaml inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another set of examples to source a bioimage.io model\n",
    "# 1. version unspecific (implicitly refering to the latest version):\n",
    "MODEL_ID = \"emotional-cricket\"\n",
    "MODEL_DOI = \"10.5281/zenodo.6346511\"\n",
    "\n",
    "# 2. version specific\n",
    "MODEL_VERSION_ID = \"emotional-cricket/1\"  # not yet available for this legacy model\n",
    "MODEL_VERSION_DOI = \"10.5281/zenodo.7768142\"\n",
    "\n",
    "# 3. an uploaded draft\n",
    "MODEL_DRAFT = \"emotional-cricket/draft\"\n",
    "\n",
    "# 4. from source\n",
    "MODEL_URL = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/emotional-cricket/1/files/rdf.yaml\"\n",
    "MODEL_PATH = \"some/local/rdf.yaml\"\n",
    "MODEL_PACKAGE_PATH = \"some/local/package.zip\"  # with an rdf.yaml inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec import InvalidDescr, load_description\n",
    "from bioimageio.spec.model.v0_5 import ModelDescr\n",
    "\n",
    "source = MODEL_DRAFT  # let's use the latest draft version\n",
    "\n",
    "loaded_description = load_description(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Validation summary of the model\n",
    "A model description is validated with our format specification. \n",
    "To inspect the corresponding validation summary access the `validation_summary` attribute.\n",
    "\n",
    "The validation summary will indicate:\n",
    "- the version of the `bioimageio.spec` library used to run the validation\n",
    "- the status of several validation steps\n",
    "    - ✔️: Success\n",
    "    - 🔍: information about the validation context\n",
    "    - ⚠: Warning\n",
    "    - ❌: Error\n",
    "\n",
    "To display the validaiton summary in a terminal or notebook we recommend to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_description.validation_summary.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make sure we have a valid model...\n",
    "if isinstance(loaded_description, InvalidDescr):\n",
    "    raise ValueError(f\"Failed to load {source}\")\n",
    "elif not isinstance(loaded_description, ModelDescr):\n",
    "    raise ValueError(\"This notebook expects a model 0.5 description\")\n",
    "\n",
    "model = loaded_description\n",
    "example_model_id = model.id\n",
    "assert example_model_id is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect the model description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import imageio.v3\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from bioimageio.spec._internal.io import FileSource\n",
    "from bioimageio.spec.utils import download\n",
    "\n",
    "\n",
    "def imread(src: FileSource) -> NDArray[Any]:\n",
    "    \"\"\"typed `imageio.v3.imread`\"\"\"\n",
    "    img: NDArray[Any] = imageio.v3.imread(download(src).path)\n",
    "    return img\n",
    "\n",
    "print(f\"The model is named '{model.name}'\")\n",
    "print(f\"Description:\\n{model.description}\")\n",
    "print(f\"License: {model.license}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from devtools import pprint\n",
    "except ImportError:\n",
    "    from pprint import pprint\n",
    "\n",
    "print(\"\\nThe authors of the model are:\")\n",
    "pprint(model.authors)\n",
    "print(f\"\\nIn addition to the authors it is maintained by:\")\n",
    "pprint(model.maintainers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nIf you use this model, you are expected to cite:\")\n",
    "pprint(model.cite)\n",
    "\n",
    "print(f\"\\nFurther documentation can be found here: {model.documentation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.git_repo is None:\n",
    "    print(\"\\nThere is no associated GitHub repository.\")\n",
    "else:\n",
    "    print(f\"\\nThere is an associated GitHub repository: {model.git_repo}.\")\n",
    "\n",
    "for i, cover in enumerate(model.covers):\n",
    "    downloaded_cover = download(cover)\n",
    "    cover_data: NDArray[Any] = imread(downloaded_cover.path)\n",
    "    _ = plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cover_data)  # type: ignore\n",
    "    plt.xticks([])  # type: ignore\n",
    "    plt.yticks([])  # type: ignore\n",
    "    plt.title(f\"cover image {downloaded_cover.original_file_name}\")  # type: ignore\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec.utils import download\n",
    "\n",
    "cover_path = download(model.covers[0]).path\n",
    "plt.imshow(imread(cover_path))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Inspect Available weight formats of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [(weights := model.weights).onnx, weights.keras_hdf5, weights.tensorflow_js, weights.tensorflow_saved_model_bundle, weights.torchscript,weights.pytorch_state_dict]:\n",
    "    if w is  None:\n",
    "        continue\n",
    "\n",
    "    print(w.weights_format_name)\n",
    "    print(f\"weights are available at {w.source.absolute()}\")\n",
    "    print(f\"and have a SHA-256 value of {w.sha256}\")\n",
    "    details = {k: v for k, v in w.model_dump(mode=\"json\", exclude_none=True).items() if k not in (\"source\", \"sha256\")}\n",
    "    if details:\n",
    "        print(f\"additonal metadata for {w.weights_format_name}:\")\n",
    "        pprint(details)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Inspect expected inputs and outputs of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model '{model.name}' requires {len(model.inputs)} input(s) with the following features:\")\n",
    "for ipt in model.inputs:\n",
    "    print(f\"\\ninput '{ipt.id}' with axes:\")\n",
    "    pprint(ipt.axes)\n",
    "    print(f\"Data description: {ipt.data}\")\n",
    "    print(f\"Test tensor available at:  {ipt.test_tensor.source.absolute()}\")\n",
    "    if len(ipt.preprocessing) > 1:\n",
    "        print(\"This input is preprocessed with: \")\n",
    "        for p in ipt.preprocessing:\n",
    "            print(p)\n",
    "\n",
    "print(\"\\n-------------------------------------------------------------------------------\")\n",
    "# # and what the model outputs are\n",
    "print(f\"Model '{model.name}' requires {len(model.outputs)} output(s) with the following features:\")\n",
    "for out in model.outputs:\n",
    "    print(f\"\\noutput '{out.id}' with axes:\")\n",
    "    pprint(out.axes)\n",
    "    print(f\"Data description: {out.data}\")\n",
    "    print(f\"Test tensor available at:  {out.test_tensor.source.absolute()}\")\n",
    "    if len(out.postprocessing) > 1:\n",
    "        print(\"This output is postprocessed with: \")\n",
    "        for p in out.postprocessing:\n",
    "            print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Inspect model architecture\n",
    "\n",
    "(inspection in this notebook only implemented for pytorch state dict weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import assert_never\n",
    "\n",
    "from bioimageio.spec.model.v0_5 import (\n",
    "    ArchitectureFromFileDescr,\n",
    "    ArchitectureFromLibraryDescr,\n",
    ")\n",
    "\n",
    "assert isinstance(model, ModelDescr)\n",
    "if (w:=model.weights.pytorch_state_dict) is not None:\n",
    "    arch = w.architecture\n",
    "    print(f\"callable: {arch.callable}\")\n",
    "    if isinstance(arch, ArchitectureFromFileDescr):\n",
    "        print(f\"import from file: {arch.source.absolute()}\")\n",
    "        if arch.sha256 is not None:\n",
    "            print(f\"SHA-256: {arch.sha256}\")\n",
    "    elif isinstance(arch, ArchitectureFromLibraryDescr):\n",
    "        print(f\"import from module: {arch.import_from}\")\n",
    "    else:\n",
    "        assert_never(arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Inspect it all!\n",
    "\n",
    "Of course we can also inspect the model description in full detail...\n",
    "(which is a lot of text and the reason we have a `ModelDescr` object in the first place that keeps this metadata more organized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a model description\n",
    "\n",
    "Let's recreate a model based on parts of the loaded model description from above!\n",
    "\n",
    "Creating a model description with bioimageio.spec means creating a `bioimageio.spec.model.ModelDescr` object. This description object can be exportet and uploaded to the BioImage Model Zoo or deployed directly with community partner software.\n",
    "\n",
    "\n",
    "Without any input data, initializing a `ModelDescr` will raise a `ValidationError` listing missing required fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec.model.v0_5 import ModelDescr\n",
    "\n",
    "_ = ModelDescr()  # pyright: ignore[reportCallIssue]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To populate a `ModelDescr` appropriately we need to create the required subparts. This is part of the model metadata needed to document the model and ensure its correct deployment.\n",
    "\n",
    "### 5.1 Inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec.model.v0_5 import (\n",
    "    AxisId,\n",
    "    BatchAxis,\n",
    "    ChannelAxis,\n",
    "    FileDescr,\n",
    "    Identifier,\n",
    "    InputTensorDescr,\n",
    "    IntervalOrRatioDataDescr,\n",
    "    ParameterizedSize,\n",
    "    SpaceInputAxis,\n",
    "    SpaceOutputAxis,\n",
    "    TensorId,\n",
    "    WeightsDescr,\n",
    ")\n",
    "\n",
    "input_axes = [\n",
    "    BatchAxis(),\n",
    "    ChannelAxis(channel_names=[Identifier(\"raw\")])]\n",
    "if len(model.inputs[0].axes)==5: # e.g. impartial-shrimp\n",
    "    input_axes += [\n",
    "        SpaceInputAxis(id=AxisId(\"z\"), size=ParameterizedSize(min=16, step=8)),\n",
    "        SpaceInputAxis(id=AxisId('y'), size=ParameterizedSize(min=144, step=72)),\n",
    "        SpaceInputAxis(id=AxisId('x'), size=ParameterizedSize(min=144, step=72)),\n",
    "    ]\n",
    "    data_descr = IntervalOrRatioDataDescr(type=\"float32\")\n",
    "elif len(model.inputs[0].axes)==4: # e.g. pioneering-rhino\n",
    "    input_axes += [\n",
    "        SpaceInputAxis(id=AxisId('y'), size=ParameterizedSize(min=256, step=8)),\n",
    "        SpaceInputAxis(id=AxisId('x'), size=ParameterizedSize(min=256, step=8)),\n",
    "    ]\n",
    "    data_descr = IntervalOrRatioDataDescr(type=\"float32\")\n",
    "else:\n",
    "    raise NotImplementedError(f\"Recreating inputs for {example_model_id} is not implemented\")\n",
    "\n",
    "test_input_path = model.inputs[0].test_tensor.download().path\n",
    "input_descr = InputTensorDescr(id=TensorId(\"raw\"), axes=input_axes, test_tensor=FileDescr(source=test_input_path), data=data_descr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec.model.v0_5 import OutputTensorDescr, SizeReference\n",
    "\n",
    "assert isinstance(model.outputs[0].axes[1], ChannelAxis)\n",
    "output_axes = [\n",
    "    BatchAxis(),\n",
    "    ChannelAxis(channel_names=[Identifier(n) for n in model.outputs[0].axes[1].channel_names])]\n",
    "if len(model.outputs[0].axes) == 5: # e.g. impartial-shrimp\n",
    "    output_axes += [\n",
    "        SpaceOutputAxis(id=AxisId(\"z\"), size=SizeReference(tensor_id=TensorId(\"raw\"), axis_id=AxisId(\"z\"))), # same size as input (tensor `raw`) axis `z`\n",
    "        SpaceOutputAxis(id=AxisId('y'), size=SizeReference(tensor_id=TensorId(\"raw\"), axis_id=AxisId(\"y\"))),\n",
    "        SpaceOutputAxis(id=AxisId('x'), size=SizeReference(tensor_id=TensorId(\"raw\"), axis_id=AxisId(\"x\")))\n",
    "    ]\n",
    "elif len(model.outputs[0].axes) == 4: # e.g. pioneering-rhino\n",
    "    output_axes += [\n",
    "        SpaceOutputAxis(id=AxisId(\"y\"), size=SizeReference(tensor_id=TensorId('raw'), axis_id=AxisId('y'))), # same size as input (tensor `raw`) axis `y`\n",
    "        SpaceOutputAxis(id=AxisId(\"x\"), size=SizeReference(tensor_id=TensorId('raw'), axis_id=AxisId('x'))),\n",
    "    ]\n",
    "else:\n",
    "    raise NotImplementedError(f\"Recreating outputs for {example_model_id} is not implemented\")\n",
    "\n",
    "test_output_path = model.outputs[0].test_tensor.download().path\n",
    "output_descr = OutputTensorDescr(id=TensorId(\"prob\"), axes=output_axes, test_tensor=FileDescr(source=test_output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Model architecture\n",
    "PyTorch state dict type of weights need to come with the corresponding architecture (e.g., 2D-U-Net):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec.model.v0_5 import (\n",
    "    ArchitectureFromFileDescr,\n",
    "    ArchitectureFromLibraryDescr,\n",
    "    Version,\n",
    ")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except ImportError:\n",
    "    pytorch_version = Version(\"1.15\")\n",
    "else:\n",
    "    pytorch_version = Version(torch.__version__)\n",
    "\n",
    "## Recover the architecture information from the original model\n",
    "assert model.weights.pytorch_state_dict is not None\n",
    "\n",
    "arch = model.weights.pytorch_state_dict.architecture\n",
    "if isinstance(arch, ArchitectureFromFileDescr):\n",
    "    arch_file_path = download(arch.source, sha256=arch.sha256).path\n",
    "    arch_file_sha256 = arch.sha256\n",
    "    arch_name = arch.callable\n",
    "    arch_kwargs = arch.kwargs\n",
    "\n",
    "    pytorch_architecture = ArchitectureFromFileDescr(\n",
    "        source=arch_file_path,\n",
    "        sha256=arch_file_sha256,\n",
    "        callable=arch_name,\n",
    "        kwargs=arch_kwargs\n",
    "    )\n",
    "else:\n",
    "    # For a model architecture that is published in a Python package\n",
    "    # Make sure to include the Python library referenced in `import_from` in the weights entry's `depdendencies`\n",
    "    pytorch_architecture = ArchitectureFromLibraryDescr(\n",
    "        callable=arch.callable,\n",
    "        kwargs=arch.kwargs,\n",
    "        import_from=arch.import_from,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec.model.v0_5 import (\n",
    "    Author,\n",
    "    CiteEntry,\n",
    "    Doi,\n",
    "    HttpUrl,\n",
    "    LicenseId,\n",
    "    PytorchStateDictWeightsDescr,\n",
    "    TorchscriptWeightsDescr,\n",
    ")\n",
    "\n",
    "assert model.weights.pytorch_state_dict is not None\n",
    "assert model.weights.torchscript is not None\n",
    "my_model_descr = ModelDescr(\n",
    "    name=\"My cool model\",\n",
    "    description=\"A test model for demonstration purposes only\",\n",
    "    authors=[Author(name=\"me\", affiliation=\"my institute\", github_user=\"bioimageiobot\")],  # change github_user to your GitHub account name\n",
    "    cite=[CiteEntry(text=\"for model training see my paper\", doi=Doi(\"10.1234something\"))],\n",
    "    license=LicenseId(\"MIT\"),\n",
    "    documentation=HttpUrl(\"https://raw.githubusercontent.com/bioimage-io/spec-bioimage-io/main/README.md\"),\n",
    "    git_repo=HttpUrl(\"https://github.com/bioimage-io/spec-bioimage-io\"),  # change to repo where your model is developed\n",
    "    inputs=model.inputs,\n",
    "    # inputs=[input_descr],  # try out our recreated input description\n",
    "    outputs=model.outputs,\n",
    "    # outputs=[output_descr],  # try out our recreated input description\n",
    "    weights=WeightsDescr(\n",
    "        pytorch_state_dict=PytorchStateDictWeightsDescr(\n",
    "            source=model.weights.pytorch_state_dict.source,\n",
    "            sha256=model.weights.pytorch_state_dict.sha256,\n",
    "            architecture=pytorch_architecture,\n",
    "            pytorch_version=pytorch_version\n",
    "        ),\n",
    "        torchscript=TorchscriptWeightsDescr(\n",
    "            source=model.weights.torchscript.source,\n",
    "            sha256=model.weights.torchscript.sha256,\n",
    "            pytorch_version=pytorch_version,\n",
    "            parent=\"pytorch_state_dict\", # these weights were converted from the pytorch_state_dict weights ones.\n",
    "        ),\n",
    "    ),\n",
    "    )\n",
    "print(f\"created '{my_model_descr.name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Covers\n",
    "Some optional fields were filed with default values, e.g., we did not specify `covers`. \n",
    "When possible, a default visualization of the test inputs and test outputs is generated.\n",
    "When the input or the output have more than one channel, the current implementation cannot generate a cover image automatically.\n",
    "\n",
    "Automatically generated cover images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cover in my_model_descr.covers:\n",
    "    img: NDArray[Any] = imread(download(cover).path)\n",
    "    _ = plt.imshow(img)\n",
    "    plt.xticks([])  # type: ignore\n",
    "    plt.yticks([])  # type: ignore\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the recently exported model\n",
    "### 6.1 Static validation\n",
    "(Same validation as at the very beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validation_summary.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Dynamic validation\n",
    "\n",
    "If you have the `bioimageio.core` library installed, you can run the dynamic validation and test if the model is correct and properly producing the test output image from the test input image. \n",
    "This extends the validation summary from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import test_model\n",
    "\n",
    "summary = test_model(my_model_descr)\n",
    "summary.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Package your model\n",
    "\n",
    "A model is more than it's YAML description file! We refer to a zip-file containing all files relevant to a model as a model package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from bioimageio.spec import save_bioimageio_package\n",
    "\n",
    "print(\"package path:\", save_bioimageio_package(my_model_descr, output_path=Path('my_model.zip')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
